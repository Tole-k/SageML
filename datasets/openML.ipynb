{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decorify import time_limiter\n",
    "from openml import tasks, runs\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_sets = ['analcatdata_asbestos', 'analcatdata_boxing1', 'analcatdata_broadwaymult', 'analcatdata_germangss', 'analcatdata_lawsuit', 'ar4', 'autos', 'baseball', 'bodyfat', 'braziltourism', 'chatfield_4', 'chscase_vine1', 'cloud', 'diabetes', 'diggle_table_a2', 'disclosure_z', 'elusage', 'fri_c0_250_5', 'kc3', 'kidney', 'labor', 'lowbwt', 'lupus',\n",
    "                'meta', 'mfeat-karhunen', 'mfeat-morphological', 'newton_hema', 'no2', 'plasma_retinol', 'pm10', 'prnn_synth', 'rabe_131', 'rmftsa_sleepdata', 'schizo', 'schlvote', 'sleuth_case2002', 'socmob', 'solar-flare', 'squash-stored', 'squash-unstored', 'tae', 'teachingAssistant', 'transplant', 'triazines', 'veteran', 'visualizing_livestock', 'vote', 'white-clover']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_ids = [\n",
    "    3550, 3540, 3824, 3887, 3542, 3911, 9, 2077, 3644, 2078, 3685, 3680, 3753, 37, 3683, 3794, 3655, 3642, 3915, 3808, 4, 3804, 3562, 3623, 16, 18, 3649, 3749, 3778, 3616, 3555, 3788, 3607, 3557, 3713, 3765, 3797, 2068, 3835, 3848, 47, 3949, 3748, 3653, 3585, 3731, 55, 3872\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"../turbo_ml/meta_learning/meta_model/algorthm_families.json\", \"r\") as f:\n",
    "    algorithm_families = json.load(f)\n",
    "inv_map = {}\n",
    "families = algorithm_families.keys()\n",
    "for k, v in algorithm_families.items():\n",
    "    for i in v:\n",
    "        inv_map[i] = k\n",
    "families"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {name: {family: [] for family in families} for name in missing_sets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unrececognized_flows = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "for id, name in zip(missing_ids, missing_sets):\n",
    "    print(name)\n",
    "    runs_df = runs.list_runs(task=[id], output_format='dataframe')\n",
    "    run_ids = runs_df['run_id'].tolist()\n",
    "    random.shuffle(run_ids)\n",
    "    for run_id in run_ids[:100]:\n",
    "        run = runs.get_run(run_id)\n",
    "        desc = run.__str__()\n",
    "        try:\n",
    "            metric = re.search(\n",
    "                r'Metric.{10}: ([^\\s]+)', desc).group(0).split(': ')[-1]\n",
    "            flow_name = re.search(\n",
    "                r'Flow Name[.]+: ([^\\s]+)', desc).group(0).split(': ')[-1].split('(')[0]\n",
    "            result = re.search(\n",
    "                r'Result.{10}: 0.[0-9]+', desc).group(0).split(': ')[-1]\n",
    "        except AttributeError:\n",
    "            continue\n",
    "        if metric != 'predictive_accuracy':\n",
    "            continue\n",
    "        if flow_name[:5] == 'weka.':\n",
    "            flow_name = ('_').join([flow_name[5:], 'w'])\n",
    "\n",
    "        if flow_name in inv_map:\n",
    "            family = inv_map[flow_name]\n",
    "        else:\n",
    "            if \"bagging\" in flow_name.lower():\n",
    "                family = \"Bagging_(BAG)\"\n",
    "            elif \"boost\" in flow_name.lower():\n",
    "                family = \"Boosting_(BST)\"\n",
    "            elif \"bayes\" in flow_name.lower():\n",
    "                family = \"Bayesian_Methods_(BY)\"\n",
    "            elif \"nn\" in flow_name.lower():\n",
    "                family = \"Neural_Networks_(NNET)\"\n",
    "            elif \"svm\" in flow_name.lower():\n",
    "                family = \"Support_Vector_Machines_(SVM)\"\n",
    "            elif \"logistic\" in flow_name.lower():\n",
    "                family = \"Logistic_and_Multinomial_Regression_(LMR)\"\n",
    "            elif \"forest\" in flow_name.lower():\n",
    "                family = \"Random_Forests_(RF)\"\n",
    "            else:\n",
    "                unrececognized_flows.append(flow_name)\n",
    "                continue\n",
    "        # print(family, flow_name, result)\n",
    "        scores[name][family].append(float(result))\n",
    "    for family in families:\n",
    "        if len(scores[name][family]) == 0:\n",
    "            scores[name][family] = 0\n",
    "        else:\n",
    "            scores[name][family] = max(scores[name][family])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame.from_dict(scores)\n",
    "\n",
    "df = df.T\n",
    "df.reset_index(inplace=True)\n",
    "df.rename(columns={'index': 'name'}, inplace=True)\n",
    "df.set_index('name', inplace=True)\n",
    "df.to_csv(\"../data/missing_family_scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(algorithm_families.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "genai.configure(api_key=\"YOUR-API-KEY\")\n",
    "\n",
    "prompt = \"What is the algorithm family of the algorithm?\"\n",
    "response_schema = {\n",
    "     \"type\": \"STRING\",\n",
    "     \"enum\": ['Discriminant Analysis',\n",
    "               'Bayesian Methods',\n",
    "               'Neural Networks',\n",
    "               'SVM',\n",
    "               'Decision Trees',\n",
    "               'Rule-Based Methods',\n",
    "               'Boosting',\n",
    "               'Bagging',\n",
    "               'Stacking',\n",
    "               'Random Forests',\n",
    "               'Other Ensembles',\n",
    "               'Generalized Linear Models',\n",
    "               'Nearest Neighbor Methods',\n",
    "               'Partial Least Squares and Principal Component Regression',\n",
    "               'Logistic and Multinomial Regression',\n",
    "               'Multivariate Adaptive Regression Splines',\n",
    "               'Other Methods'\n",
    "          ],\n",
    "}\n",
    "model = genai.GenerativeModel(\n",
    "    system_instruction=prompt,\n",
    "    generation_config=genai.GenerationConfig(\n",
    "        response_mime_type=\"text/x.enum\", response_schema=response_schema\n",
    "    ),\n",
    ")\n",
    "\n",
    "@time_limiter(60, 14) # 15 requests per minute (I left one out as buffer)\n",
    "def classify_algorithm(name):\n",
    "     response = model.generate_content(name)\n",
    "     print(response.usage_metadata.total_token_count)\n",
    "     return response.text\n",
    "\n",
    "mapping = {}\n",
    "for name in set(unrececognized_flows):\n",
    "     mapping[name] = classify_algorithm(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"classification.json\", \"w\") as f:\n",
    "    json.dump(mapping, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
